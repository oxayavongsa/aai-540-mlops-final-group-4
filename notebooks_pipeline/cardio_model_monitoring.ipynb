{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d097e62-2546-47c0-9b15-31d2587e39f5",
   "metadata": {},
   "source": [
    "## Model Monitoring Setup: Data Capture, Baseline Generation, Deployment Preparation for Model Quality Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ebb3604-fada-4a50-8bfb-22161d040510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Setup\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session\n",
    "from sagemaker.model_monitor import DataCaptureConfig, DefaultModelMonitor\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba491b2-cb7a-47dd-9984-e0dd87d585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Location and Inference Code\n",
    "model_artifact = 's3://sagemaker-us-east-1-531690656306/model/logistic_model.tar.gz'\n",
    "entry_point = 'inference.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ebd1e3-fc98-45b5-ad7d-0921c3fa9124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker session initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Session\n",
    "session = Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# Initialize SageMaker low-level boto3 client\n",
    "sagemaker_client = boto3.client('sagemaker', region_name='us-east-1')\n",
    "\n",
    "# Define key variables\n",
    "region = 'us-east-1'\n",
    "bucket = 'sagemaker-us-east-1-531690656306'  # Thai's S3 bucket\n",
    "model_artifact = f's3://{bucket}/model/logistic_model.tar.gz'  # Thai's model path\n",
    "entry_point = 'inference.py'\n",
    "\n",
    "print(\"SageMaker session initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7339a1a5-6c21-4e18-bf01-4eedee1e9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SKLearn Model Object\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    entry_point=entry_point,\n",
    "    framework_version='0.23-1',\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d064519-642a-45a5-97ba-f4d1276abcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Capture Config\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=f's3://{bucket}/data-capture',\n",
    "    capture_options=['Request', 'Response']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d447eb66-fcaf-4be7-840e-3bcaebc6f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy Function With If-Else Check\n",
    "def deploy_if_not_exists(model, endpoint_name, instance_type, data_capture_config=None):\n",
    "    try:\n",
    "        sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Endpoint '{endpoint_name}' already exists. Skipping deployment.\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ValidationException':\n",
    "            print(f\"Endpoint '{endpoint_name}' not found. Deploying new endpoint...\")\n",
    "            model.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                data_capture_config=data_capture_config\n",
    "            )\n",
    "            print(\"Deployment completed.\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86a9b02-0361-416d-acd9-a27d0de9e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint 'cardio-logistic-monitor-endpoint' already exists. Skipping deployment.\n"
     ]
    }
   ],
   "source": [
    "# Call Deployment Function\n",
    "endpoint_name = 'cardio-logistic-monitor-endpoint'\n",
    "deploy_if_not_exists(\n",
    "    model=sklearn_model,\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3beb2bc8-411f-44fd-98d0-0de80c478336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Baseline for Model Monitor\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b04a8a-7331-45ff-9b22-b816d8f8b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Baseline URIs\n",
    "baseline_data_uri = 's3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered.csv'\n",
    "baseline_results_uri = 's3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b75daa5-ef5d-4c93-b447-b672cc9c60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2025-06-06-07-24-20-695\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..............\u001b[34m2025-06-06 07:26:32.724364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:32.724391: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:34.277690: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:34.277720: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:34.277744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-70-159.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:34.278024: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:531690656306:processing-job/baseline-suggestion-job-2025-06-06-07-24-20-695', 'ProcessingJobName': 'baseline-suggestion-job-2025-06-06-07-24-20-695', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::531690656306:role/LabRole', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,823 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,884 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,885 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,885 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0', 'topology': None}\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,894 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,894 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:35,894 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,343 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.2.70.159\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-ap\u001b[0m\n",
      "\u001b[34mplications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,350 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,353 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-902bad77-65af-419d-a309-24caea6b7fd5\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,839 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,850 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,851 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,853 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,858 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,858 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,858 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,858 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,887 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,898 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,898 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,903 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,906 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Jun 06 07:26:36\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,907 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,907 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,908 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,908 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,942 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,946 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,971 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,971 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,971 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,971 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,973 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,973 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,973 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,974 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,978 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,981 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,981 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,981 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:36,981 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,018 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,018 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,018 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,022 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,022 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,023 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,023 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,023 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 975.5 KB\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,024 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,044 INFO namenode.FSImage: Allocated new BlockPoolId: BP-278135043-10.2.70.159-1749194797038\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,057 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,064 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,144 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,156 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,159 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.70.159\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:37,171 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:39,228 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:39,228 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:41,296 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:41,296 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:43,358 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:43,359 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:45,447 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:45,447 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:47,569 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:47,570 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:57,578 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:59,258 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:59,664 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:59,704 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:26:59,717 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,307 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,332 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,333 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,333 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,334 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,364 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11507, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,378 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,380 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,437 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,437 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,437 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,438 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,438 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,764 INFO util.Utils: Successfully started service 'sparkDriver' on port 36431.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,792 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,828 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,844 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,845 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,878 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,900 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-3c415db5-645c-46d2-a2c1-1115c02be879\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,915 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,951 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:00,982 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.70.159:36431/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1749194820303\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:01,440 INFO client.RMProxy: Connecting to ResourceManager at /10.2.70.159:8032\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,130 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,130 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,136 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15692 MB per container)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,137 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,137 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,138 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,144 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:02,223 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:04,499 INFO yarn.Client: Uploading resource file:/tmp/spark-27b4bb8d-6199-4a61-86f7-d565ee73c86d/__spark_libs__268203754123365002.zip -> hdfs://10.2.70.159/user/root/.sparkStaging/application_1749194802873_0001/__spark_libs__268203754123365002.zip\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:05,653 INFO yarn.Client: Uploading resource file:/tmp/spark-27b4bb8d-6199-4a61-86f7-d565ee73c86d/__spark_conf__1130696564337093422.zip -> hdfs://10.2.70.159/user/root/.sparkStaging/application_1749194802873_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,095 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,095 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,095 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,095 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,095 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,121 INFO yarn.Client: Submitting application application_1749194802873_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:06,310 INFO impl.YarnClientImpl: Submitted application application_1749194802873_0001\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:07,315 INFO yarn.Client: Application report for application_1749194802873_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:07,319 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1749194826214\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1749194802873_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:08,321 INFO yarn.Client: Application report for application_1749194802873_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:09,324 INFO yarn.Client: Application report for application_1749194802873_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:10,337 INFO yarn.Client: Application report for application_1749194802873_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,218 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1749194802873_0001), /proxy/application_1749194802873_0001\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,341 INFO yarn.Client: Application report for application_1749194802873_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,341 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.2.70.159\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1749194826214\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1749194802873_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,343 INFO cluster.YarnClientSchedulerBackend: Application application_1749194802873_0001 has started running.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,370 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45705.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,370 INFO netty.NettyBlockTransferService: Server created on 10.2.70.159:45705\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,372 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,381 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.2.70.159, 45705, None)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,386 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.2.70.159:45705 with 1458.6 MiB RAM, BlockManagerId(driver, 10.2.70.159, 45705, None)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,389 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.2.70.159, 45705, None)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,390 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.2.70.159, 45705, None)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:11,599 INFO util.log: Logging initialized @13768ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:12,664 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:17,050 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.70.159:52940) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:17,221 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:42115 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 42115, None)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:31,371 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:31,582 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:31,637 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:31,643 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:32,712 INFO datasources.InMemoryFileIndex: It took 36 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:32,869 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,163 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,166 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.2.70.159:45705 (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,173 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,498 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,501 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,506 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,554 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,572 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,573 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,573 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,575 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,580 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,631 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,634 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,635 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.2.70.159:45705 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,636 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,651 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,652 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,692 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4630 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:33,922 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:42115 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:34,680 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:42115 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,010 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1332 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,049 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,057 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.453 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,068 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,068 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,070 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.516313 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,228 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.2.70.159:45705 in memory (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,229 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:42115 in memory (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,249 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.2.70.159:45705 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:35,251 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:42115 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,247 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,249 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,252 INFO datasources.FileSourceStrategy: Output Data Schema: struct<age: string, gender: string, height_ft: string, weight_lbs: string, systolic_bp: string ... 22 more fields>\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,438 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,452 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,453 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.2.70.159:45705 (size: 39.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,454 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,469 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,513 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,514 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,514 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,515 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,517 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,519 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,580 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.9 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,582 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,582 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.2.70.159:45705 (size: 8.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,583 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,584 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,585 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,589 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:37,632 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:42115 (size: 8.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:38,454 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:42115 (size: 39.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,660 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:42115 (size: 3.2 MiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,799 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2213 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,799 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,800 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 2.278 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,805 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,805 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:39,806 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 2.292537 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,113 INFO codegen.CodeGenerator: Code generated in 230.081826 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,585 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,729 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,733 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,734 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,734 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,737 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,740 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,763 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 116.6 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,765 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,766 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.2.70.159:45705 (size: 35.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,767 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,769 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,769 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,778 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:40,822 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:42115 (size: 35.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,708 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1932 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,708 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,710 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.967 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,710 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,711 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,711 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,711 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,783 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,786 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,786 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,786 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,786 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,787 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,803 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 169.3 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,806 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 46.7 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,806 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.2.70.159:45705 (size: 46.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,807 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,808 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,808 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,811 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,834 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:42115 (size: 46.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:42,875 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,283 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 473 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,283 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,284 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.489 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,285 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,285 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,285 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.502075 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,339 INFO codegen.CodeGenerator: Code generated in 44.05563 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,607 INFO codegen.CodeGenerator: Code generated in 33.330616 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,676 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,677 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,678 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,678 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,679 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,680 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,706 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 40.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,708 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,709 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.2.70.159:45705 (size: 17.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,710 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,711 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,711 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,713 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:43,733 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:42115 (size: 17.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,441 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 1729 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,442 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 1.758 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,442 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,442 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,442 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,443 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 1.766380 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,918 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.2.70.159:45705 in memory (size: 46.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,921 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:42115 in memory (size: 46.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,965 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.2.70.159:45705 in memory (size: 17.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:45,966 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:42115 in memory (size: 17.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,003 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.2.70.159:45705 in memory (size: 35.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,011 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:42115 in memory (size: 35.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,019 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.2.70.159:45705 in memory (size: 8.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,020 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:42115 in memory (size: 8.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,047 INFO codegen.CodeGenerator: Code generated in 129.34454 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,055 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,056 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,056 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,056 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,057 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,058 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,062 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 77.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,065 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.9 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,065 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.2.70.159:45705 (size: 24.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,066 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,067 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,067 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,068 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,080 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:42115 (size: 24.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,346 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 278 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,347 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,347 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.288 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,348 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,348 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,348 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,348 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,515 INFO codegen.CodeGenerator: Code generated in 81.468991 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,527 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,529 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,529 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,529 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,529 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,532 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,535 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 67.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,541 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,541 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.2.70.159:45705 (size: 19.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,542 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,543 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,543 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,544 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,557 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:42115 (size: 19.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,562 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,648 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 104 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,648 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,651 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.117 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,651 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,651 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,651 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.123561 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,780 INFO codegen.CodeGenerator: Code generated in 96.265667 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,918 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,922 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,922 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,922 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,922 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,922 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,926 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,936 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 32.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,938 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,939 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.2.70.159:45705 (size: 14.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,939 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,940 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,940 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,942 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:46,956 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:42115 (size: 14.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,494 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1551 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,494 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,495 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.568 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,498 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,499 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,499 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,499 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,500 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,502 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,507 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,507 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.2.70.159:45705 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,508 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,509 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,509 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,512 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,529 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:42115 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,535 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,578 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,579 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,580 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.079 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,581 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,581 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,581 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.662877 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,810 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,810 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,810 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,811 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,813 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,814 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,819 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 85.6 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,822 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,823 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.2.70.159:45705 (size: 28.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,824 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,824 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,825 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,828 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:48,842 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:42115 (size: 28.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,250 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 422 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,251 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,251 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.436 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,251 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,251 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,251 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,252 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,285 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,286 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,286 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,286 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,286 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,287 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,293 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 170.4 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,295 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,296 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.2.70.159:45705 (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,296 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,297 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,297 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,298 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,306 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:42115 (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,315 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,421 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 124 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,421 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,422 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.134 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,422 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,422 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,423 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.138089 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,542 INFO codegen.CodeGenerator: Code generated in 12.478187 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,574 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,575 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,575 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,575 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,575 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,577 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,582 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,584 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,585 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.2.70.159:45705 (size: 16.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,585 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,585 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,585 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,587 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:49,596 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:42115 (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,918 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 1331 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,919 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,919 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 1.341 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,920 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,920 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:50,920 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 1.346138 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,146 INFO codegen.CodeGenerator: Code generated in 48.303619 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,154 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,154 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,154 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,154 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,155 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,155 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,160 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 78.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,163 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,163 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.2.70.159:45705 (size: 25.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,164 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,164 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,164 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,165 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,178 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:42115 (size: 25.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,369 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 204 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,369 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,370 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.212 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,371 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,371 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,371 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,371 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,481 INFO codegen.CodeGenerator: Code generated in 56.541472 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,491 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,492 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,492 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,492 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,492 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,493 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,494 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 67.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,496 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,496 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.2.70.159:45705 (size: 19.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,497 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,498 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,498 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,499 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,513 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:42115 (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,517 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,603 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 104 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,603 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,603 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,604 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,604 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,604 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.112983 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,666 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:42115 in memory (size: 25.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,688 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.2.70.159:45705 in memory (size: 25.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,716 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:42115 in memory (size: 28.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,724 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.2.70.159:45705 in memory (size: 28.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,742 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,746 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,746 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,746 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,747 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,747 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,747 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,753 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,754 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,755 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.2.70.159:45705 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,756 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,756 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,756 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,757 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,765 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.2.70.159:45705 in memory (size: 19.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,777 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:42115 in memory (size: 19.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,778 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:42115 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,808 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:42115 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,812 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.2.70.159:45705 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,834 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.2.70.159:45705 in memory (size: 16.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,858 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:42115 in memory (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,877 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:42115 in memory (size: 24.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,879 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.2.70.159:45705 in memory (size: 24.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,890 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.2.70.159:45705 in memory (size: 19.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,892 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:42115 in memory (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,902 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.2.70.159:45705 in memory (size: 14.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,909 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:42115 in memory (size: 14.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,925 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.2.70.159:45705 in memory (size: 47.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,934 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:42115 in memory (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,953 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 196 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,953 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.206 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,954 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,956 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,958 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,958 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.2.70.159:45705 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,959 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,960 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,960 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,961 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,969 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:42115 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,972 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,984 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,984 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,985 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,985 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,985 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:51,985 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.243201 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,133 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,134 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,134 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,134 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,134 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,135 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,139 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 85.6 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,141 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,142 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.2.70.159:45705 (size: 28.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,142 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,143 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,143 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,144 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,155 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:42115 (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,528 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 384 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,528 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,529 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.393 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,529 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,529 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,529 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,529 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,573 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,574 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,574 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,574 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,574 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,574 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,581 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 170.5 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,584 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,585 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.2.70.159:45705 (size: 46.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,592 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,592 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,592 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,594 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,605 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:42115 (size: 46.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,614 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,711 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 117 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,711 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,714 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.139 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,715 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,715 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,715 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.142192 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,799 INFO codegen.CodeGenerator: Code generated in 15.698778 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,837 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,838 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,838 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,838 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,839 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,839 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,848 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,850 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,851 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.2.70.159:45705 (size: 17.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,852 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,852 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,852 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,854 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:52,864 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:42115 (size: 17.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,694 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 840 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,695 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,695 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.855 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,696 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,696 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,696 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.859385 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,832 INFO codegen.CodeGenerator: Code generated in 39.649772 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,838 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,838 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,838 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,838 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,839 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,839 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,842 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 56.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,843 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,844 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.2.70.159:45705 (size: 19.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,844 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,846 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,846 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,847 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:53,856 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:42115 (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,006 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,006 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,011 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.171 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,012 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,012 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,012 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,012 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,142 INFO codegen.CodeGenerator: Code generated in 84.799502 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,152 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,153 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,153 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,153 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,154 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,154 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,156 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 44.4 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,158 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,159 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.2.70.159:45705 (size: 14.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,159 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,160 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,160 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,161 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,172 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:42115 (size: 14.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,176 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,244 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,244 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,245 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.090 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,245 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,245 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,247 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.093881 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,297 INFO codegen.CodeGenerator: Code generated in 42.844267 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,369 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,370 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,370 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,370 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,371 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,371 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,371 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,378 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 32.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,379 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,380 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.2.70.159:45705 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,381 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,381 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,381 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,382 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,392 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:42115 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,527 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 145 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,527 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,528 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.155 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,529 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,529 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,529 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,529 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,530 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,531 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,532 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,532 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.2.70.159:45705 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,533 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,533 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,533 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,534 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,543 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:42115 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,546 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,555 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,555 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,556 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,557 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,557 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,557 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.187951 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,649 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,649 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,649 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,649 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,650 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,650 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,655 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 85.6 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,657 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,658 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.2.70.159:45705 (size: 28.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,659 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,659 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,659 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,671 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:42115 (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,986 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 325 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,986 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,987 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.335 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,987 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,987 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,987 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:54,987 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,016 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,017 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,017 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,017 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,017 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,018 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,022 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 170.6 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,024 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,024 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.2.70.159:45705 (size: 47.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,025 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,025 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,025 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,026 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,034 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:42115 (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,042 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,134 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 108 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,134 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,135 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.116 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,135 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,135 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,135 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.118669 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,255 INFO codegen.CodeGenerator: Code generated in 13.156748 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,292 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,293 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,293 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,293 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,294 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,295 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,301 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 40.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,303 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,303 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.2.70.159:45705 (size: 17.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,308 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,309 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,309 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,310 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:55,320 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:42115 (size: 17.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,657 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 1348 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,658 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,658 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 1.362 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,659 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,659 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,659 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 1.366934 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,850 INFO codegen.CodeGenerator: Code generated in 47.848638 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,857 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,857 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,857 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,857 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,858 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,858 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,861 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 77.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,865 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,865 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.2.70.159:45705 (size: 25.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,866 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,866 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,866 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,867 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:56,879 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:42115 (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,128 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 261 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,128 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,129 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.270 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,129 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,129 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,129 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,129 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,252 INFO codegen.CodeGenerator: Code generated in 63.512757 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,279 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,282 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,282 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,282 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,282 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,283 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,284 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 67.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,289 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,289 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.2.70.159:45705 (size: 19.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,289 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,290 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,290 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,291 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,301 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:42115 (size: 19.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,304 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,374 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,374 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,375 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.092 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,375 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,376 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,376 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.094591 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,494 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,500 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,501 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,501 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,501 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,501 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,502 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,514 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:42115 in memory (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,521 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.2.70.159:45705 in memory (size: 28.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,532 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 32.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,533 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,534 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.2.70.159:45705 (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,534 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,535 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,535 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,536 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,548 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:42115 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,581 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:42115 in memory (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,587 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.2.70.159:45705 in memory (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,601 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.2.70.159:45705 in memory (size: 46.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,612 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:42115 in memory (size: 46.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,628 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:42115 in memory (size: 14.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,630 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.2.70.159:45705 in memory (size: 14.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,642 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.2.70.159:45705 in memory (size: 17.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,644 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:42115 in memory (size: 17.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,652 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.2.70.159:45705 in memory (size: 17.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,655 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:42115 in memory (size: 17.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,669 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.2.70.159:45705 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,670 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:42115 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,674 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:42115 in memory (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,676 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.2.70.159:45705 in memory (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,689 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.2.70.159:45705 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,698 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:42115 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,708 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:42115 in memory (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,713 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.2.70.159:45705 in memory (size: 14.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,718 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.2.70.159:45705 in memory (size: 19.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,719 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:42115 in memory (size: 19.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,728 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 192 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,728 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.226 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,729 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,730 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.2.70.159:45705 in memory (size: 28.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,731 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,732 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,734 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:42115 in memory (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,734 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.2.70.159:45705 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,735 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,737 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.2.70.159:45705 in memory (size: 19.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,738 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:42115 in memory (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,741 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.2.70.159:45705 in memory (size: 25.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,743 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,743 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,744 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:42115 in memory (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,744 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,752 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:42115 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,755 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,780 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,780 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,780 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,781 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,781 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,781 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.282005 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,949 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,950 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,950 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,950 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,951 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,951 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,959 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 75.4 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,962 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,963 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.2.70.159:45705 (size: 25.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,963 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,965 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,966 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,967 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:57,983 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:42115 (size: 25.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,534 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 567 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,534 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,535 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.583 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,535 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,535 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,535 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,535 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,566 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,567 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,567 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,567 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,567 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,567 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,572 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 144.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,574 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 41.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,574 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.2.70.159:45705 (size: 41.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,575 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,575 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,575 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,576 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,585 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:42115 (size: 41.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,594 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,694 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 117 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,694 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,695 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.128 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,696 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,696 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,697 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.130946 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,707 INFO codegen.CodeGenerator: Code generated in 7.816576 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,803 INFO codegen.CodeGenerator: Code generated in 14.424797 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,839 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,840 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,840 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,840 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,841 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,841 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,850 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 38.3 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,852 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,852 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.2.70.159:45705 (size: 16.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,859 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,859 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,860 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,861 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:58,870 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:42115 (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,463 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 602 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,463 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,464 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.621 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,465 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,465 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,465 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.625875 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,570 INFO codegen.CodeGenerator: Code generated in 31.076129 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,592 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,593 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,593 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,593 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,594 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,595 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,599 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 45.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,601 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,601 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.2.70.159:45705 (size: 17.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,602 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,602 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,602 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,604 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,614 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:42115 (size: 17.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,769 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 166 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,769 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,770 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.174 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,770 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,770 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,770 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,770 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,827 INFO codegen.CodeGenerator: Code generated in 25.84415 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,849 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,850 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,852 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,852 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,853 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,853 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,855 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 33.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,857 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,859 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.2.70.159:45705 (size: 11.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,860 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,861 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,861 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,862 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,872 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:42115 (size: 11.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,876 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,923 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 61 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,924 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,924 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,925 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,925 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,925 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.076185 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:27:59,955 INFO codegen.CodeGenerator: Code generated in 23.703106 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,002 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,003 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,004 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,004 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,004 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,004 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,005 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,011 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 32.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,013 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,014 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.2.70.159:45705 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,015 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,016 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,016 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,018 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,028 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:42115 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,286 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 269 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,286 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,287 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.281 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,288 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,289 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,289 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,289 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,290 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,291 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,293 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,294 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.2.70.159:45705 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,295 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,295 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,295 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,296 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,305 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:42115 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,308 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,329 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,329 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,330 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,330 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,331 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,331 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.328422 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,565 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,591 INFO codegen.CodeGenerator: Code generated in 7.036598 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,596 INFO scheduler.DAGScheduler: Registering RDD 191 (count at StatsGenerator.scala:66) as input to shuffle 15\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,597 INFO scheduler.DAGScheduler: Got map stage job 32 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,597 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,597 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,598 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,598 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,601 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 24.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,602 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,603 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.2.70.159:45705 (size: 11.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,604 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,604 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,604 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,606 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4947 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,616 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:42115 (size: 11.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,689 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 84 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,689 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,690 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (count at StatsGenerator.scala:66) finished in 0.091 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,691 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,691 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,691 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,691 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,708 INFO codegen.CodeGenerator: Code generated in 7.255962 ms\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,718 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,720 INFO scheduler.DAGScheduler: Got job 33 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,720 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,720 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,720 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,721 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,722 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,725 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,725 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.2.70.159:45705 (size: 5.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,726 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,726 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,726 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,727 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,738 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:42115 (size: 5.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,743 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.2.70.159:52940\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,756 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 29 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,756 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,757 INFO scheduler.DAGScheduler: ResultStage 49 (count at StatsGenerator.scala:66) finished in 0.036 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,757 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,757 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:00,758 INFO scheduler.DAGScheduler: Job 33 finished: count at StatsGenerator.scala:66, took 0.039037 s\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,357 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,382 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,427 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,427 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,432 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,451 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,502 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,502 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,509 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,513 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,542 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,548 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,548 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,583 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,588 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-5ac03ff2-71c6-4047-ab27-d6a8334d186a\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,602 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-27b4bb8d-6199-4a61-86f7-d565ee73c86d\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,700 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2025-06-06 07:28:01,701 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Baseline\n",
    "baseline_job = monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format={'csv': {'header': True}},\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3fc0e-fd1f-4e0e-923a-4e325d564425",
   "metadata": {},
   "source": [
    "Full model monitoring pipeline has been prepared by first creating the SKLearn model object, which wraps the trained logistic regression model and inference script so SageMaker can use it. Then I enable data capture, which collects real-time input data and predictions as the model serves traffic, creating a record of live inference data. After that, I deploy the model as an endpoint to make it accessible for inference while capturing data. Once deployed, I generate a baseline using the fully cleaned and preprocessed training dataset; this allows SageMaker to compute statistics and constraints that define the model’s expected data distributions. These baseline statistics become the reference point that future data will be compared against to detect drift or anomalies. This full setup ensures that once monitoring jobs are configured, SageMaker can automatically evaluate incoming data for shifts that may impact model accuracy or stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636aeb4-cfe1-4999-96b1-97a027ad988e",
   "metadata": {},
   "source": [
    "* Calculates <b>statistics</b> (distribution, min, max, mean, std, percentiles, etc.)\n",
    "* Generates <b>constraints</b> (rules/thresholds learned from your dataset, e.g., feature X must be within certain boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285f5f8-e12c-40cd-b2c8-55a9876ee418",
   "metadata": {},
   "source": [
    "### Check Constraint Files Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78f73e78-2dc6-465c-92d4-7f2a261f186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline statistics and constraints found:\n",
      "cardio_data/baseline-results/constraints.json\n",
      "cardio_data/baseline-results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Your bucket and baseline folder\n",
    "bucket = 'sagemaker-us-east-1-531690656306'\n",
    "baseline_prefix = 'cardio_data/baseline-results/'\n",
    "\n",
    "# List objects in the baseline folder\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=baseline_prefix)\n",
    "\n",
    "# Check and print files\n",
    "if 'Contents' in response:\n",
    "    print(\"Baseline statistics and constraints found:\")\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No baseline files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643765fb-250d-4260-9c23-7499010bef28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## For Reference Only\n",
    "### <u>File Locations Summary for Model Monitoring Setup</u>\n",
    "\n",
    "#### Trained Model Artifact (used for deployment & endpoint)\n",
    "`s3://sagemaker-us-east-1-531690656306/model/logistic_model.tar.gz`\n",
    "\n",
    "#### Training Dataset (used for baseline generation)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_train.csv`\n",
    "\n",
    "#### Engineered Dataset (cleaned and engineered)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered.csv`\n",
    "\n",
    "#### Baseline Results Output Folder (generated by model monitor baseline job)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/`\n",
    "\n",
    "#### Inside baseline-results:\n",
    "- `statistics.json`  \n",
    "  `s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/statistics.json`\n",
    "\n",
    "- `constraints.json`  \n",
    "  `s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/constraints.json`\n",
    "\n",
    "#### Data Capture Location (request/response payloads captured from endpoint)\n",
    "`s3://sagemaker-us-east-1-531690656306/data-capture/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sagemaker-env)",
   "language": "python",
   "name": "sagemaker-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
