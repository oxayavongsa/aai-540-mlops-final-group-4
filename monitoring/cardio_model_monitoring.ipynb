{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d097e62-2546-47c0-9b15-31d2587e39f5",
   "metadata": {},
   "source": [
    "## Model Monitoring Setup\n",
    "Data Capture, Baseline Generation, Deployment Preparation for Model Quality Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebb3604-fada-4a50-8bfb-22161d040510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Setup\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session\n",
    "from sagemaker.model_monitor import DataCaptureConfig, DefaultModelMonitor\n",
    "from sagemaker.sklearn.model import SKLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8337e5d1-ffe5-4c91-b402-e59817e5622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker session initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize session and role\n",
    "session = Session()\n",
    "role = get_execution_role()\n",
    "region = session.boto_region_name\n",
    "\n",
    "# Define bucket and paths\n",
    "bucket = 'sagemaker-us-east-1-531690656306'\n",
    "prefix = 'cardio_data'\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "print(\"SageMaker session initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f1151b2-b6b0-4bf2-9cc5-804ca8971ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  gender  height_ft  weight_lbs  systolic_bp  diastolic_bp  cholesterol  \\\n",
      "0   50       2       5.51      136.69          110            80            1   \n",
      "1   55       1       5.12      187.39          140            90            3   \n",
      "2   51       1       5.41      141.10          130            70            3   \n",
      "3   48       2       5.54      180.78          150           100            1   \n",
      "4   47       1       5.12      123.46          100            60            1   \n",
      "\n",
      "   gluc  smoke  alco  ...  cholesterol_label  pulse_pressure  chol_bmi_ratio  \\\n",
      "0     1      0     0  ...             Normal              30            4.55   \n",
      "1     1      0     0  ...  Well Above Normal              50            8.60   \n",
      "2     1      0     0  ...  Well Above Normal              60           12.74   \n",
      "3     1      0     0  ...             Normal              50            3.48   \n",
      "4     1      0     0  ...             Normal              40            4.35   \n",
      "\n",
      "  height_in age_years  is_hypertensive  bp_category  bmi_category  \\\n",
      "0     66.12        50                0       stage1        normal   \n",
      "1     61.44        55                1       stage2         obese   \n",
      "2     64.92        51                0       stage1        normal   \n",
      "3     66.48        48                1       stage2    overweight   \n",
      "4     61.44        47                0       normal        normal   \n",
      "\n",
      "   age_gluc_interaction  lifestyle_score  \n",
      "0                    50               -1  \n",
      "1                    55               -1  \n",
      "2                    51                0  \n",
      "3                    48               -1  \n",
      "4                    47                0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cleaned dataset uploaded to S3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your existing engineered dataset\n",
    "df = pd.read_csv('cardio_engineered.csv')\n",
    "\n",
    "# Check data\n",
    "print(df.head())\n",
    "\n",
    "# Save cleaned CSV\n",
    "clean_file = 'cardio_engineered_clean.csv'\n",
    "df.to_csv(clean_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Upload cleaned CSV to S3\n",
    "s3_client.upload_file(clean_file, bucket, f'{prefix}/cardio_engineered_clean.csv')\n",
    "\"Cleaned dataset uploaded to S3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a98909a8-e882-474f-baf3-a7011645f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and inference script\n",
    "model_artifact = f's3://{bucket}/model/logistic_model.tar.gz'\n",
    "entry_point = 'inference.py'\n",
    "endpoint_name = 'cardio-logistic-monitor-endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86282eab-2f3a-4d26-8bba-f2ff0c9bfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    entry_point=entry_point,\n",
    "    framework_version='0.23-1',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Enable full data capture\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=f's3://{bucket}/data-capture',\n",
    "    capture_options=['Request', 'Response']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d447eb66-fcaf-4be7-840e-3bcaebc6f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint 'cardio-logistic-monitor-endpoint' already exists. Skipping deployment.\n"
     ]
    }
   ],
   "source": [
    "# Deploy only if endpoint doesn't exist\n",
    "def deploy_if_not_exists(model, endpoint_name, instance_type, data_capture_config):\n",
    "    try:\n",
    "        sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Endpoint '{endpoint_name}' already exists. Skipping deployment.\")\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        if 'Could not find endpoint' in str(e):\n",
    "            model.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                data_capture_config=data_capture_config\n",
    "            )\n",
    "            print(f\"Deployed endpoint '{endpoint_name}' successfully.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# Call deployment function\n",
    "deploy_if_not_exists(\n",
    "    model=sklearn_model,\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6983fe45-b4c2-4220-ab74-65cd97b0869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2025-06-11-03-23-46-655\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered_clean.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "................\u001b[34m2025-06-11 03:26:21.434222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:21.434252: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:23.036957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:23.036988: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:23.037007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-184-7.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:23.037283: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,627 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:531690656306:processing-job/baseline-suggestion-job-2025-06-11-03-23-46-655', 'ProcessingJobName': 'baseline-suggestion-job-2025-06-11-03-23-46-655', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered_clean.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::531690656306:role/LabRole', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,628 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,628 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,628 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,628 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,628 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,690 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,691 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,691 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0', 'topology': None}\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,700 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,700 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:24,700 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,180 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.184.7\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/ya\u001b[0m\n",
      "\u001b[34mrn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,190 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,193 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-a24c38c1-eb75-40b0-addf-19cb4d287049\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,728 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,740 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,741 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,743 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,748 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,748 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,748 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,749 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,781 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,791 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,791 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,795 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,798 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Jun 11 03:26:25\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,800 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,800 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,801 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,801 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,878 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,882 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,883 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,883 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,883 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,908 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,908 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,909 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,909 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,910 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,910 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,910 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,911 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,915 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,918 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,919 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,919 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,919 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,925 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,925 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,925 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,928 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,929 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,930 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,930 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,930 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 975.5 KB\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,930 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,951 INFO namenode.FSImage: Allocated new BlockPoolId: BP-825196268-10.0.184.7-1749612385944\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,963 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:25,970 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:26,049 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:26,062 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:26,066 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.184.7\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:26,078 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:28,137 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:28,137 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:30,199 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:30,199 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:32,286 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:32,287 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:34,408 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:34,409 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:36,601 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:36,601 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:46,610 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:48,339 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:48,780 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:48,817 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:48,830 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,355 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,379 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,380 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,380 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,381 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,404 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11507, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,417 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,419 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,469 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,469 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,469 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,470 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,470 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,861 INFO util.Utils: Successfully started service 'sparkDriver' on port 44529.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,896 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,934 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,958 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,958 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:49,991 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:50,013 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-9aed4d41-e893-4eb1-89df-17de9c60cd64\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:50,030 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:50,067 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:50,099 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.184.7:44529/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1749612409351\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:50,587 INFO client.RMProxy: Connecting to ResourceManager at /10.0.184.7:8032\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,256 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,256 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,262 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15692 MB per container)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,263 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,263 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,264 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,270 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:51,347 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:53,615 INFO yarn.Client: Uploading resource file:/tmp/spark-94ffe8ea-fa6e-4dcf-8bd5-7f42cb23f7ef/__spark_libs__8352504301380535456.zip -> hdfs://10.0.184.7/user/root/.sparkStaging/application_1749612391880_0001/__spark_libs__8352504301380535456.zip\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,774 INFO yarn.Client: Uploading resource file:/tmp/spark-94ffe8ea-fa6e-4dcf-8bd5-7f42cb23f7ef/__spark_conf__6909651976251699124.zip -> hdfs://10.0.184.7/user/root/.sparkStaging/application_1749612391880_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,827 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,827 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,827 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,828 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,828 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:54,862 INFO yarn.Client: Submitting application application_1749612391880_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:55,063 INFO impl.YarnClientImpl: Submitted application application_1749612391880_0001\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:56,067 INFO yarn.Client: Application report for application_1749612391880_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:56,071 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Wed Jun 11 03:26:55 +0000 2025] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1749612414957\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1749612391880_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:57,075 INFO yarn.Client: Application report for application_1749612391880_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:58,080 INFO yarn.Client: Application report for application_1749612391880_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:26:59,082 INFO yarn.Client: Application report for application_1749612391880_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:00,087 INFO yarn.Client: Application report for application_1749612391880_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:00,523 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1749612391880_0001), /proxy/application_1749612391880_0001\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,092 INFO yarn.Client: Application report for application_1749612391880_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,092 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.184.7\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1749612414957\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1749612391880_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,097 INFO cluster.YarnClientSchedulerBackend: Application application_1749612391880_0001 has started running.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,115 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44285.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,115 INFO netty.NettyBlockTransferService: Server created on 10.0.184.7:44285\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,117 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,127 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.184.7, 44285, None)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,131 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.184.7:44285 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.184.7, 44285, None)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,134 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.184.7, 44285, None)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,135 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.184.7, 44285, None)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:01,346 INFO util.log: Logging initialized @14486ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:02,082 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:06,466 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.184.7:55354) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:06,642 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:42163 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 42163, None)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:20,539 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:20,740 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:20,790 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:20,794 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:21,866 INFO datasources.InMemoryFileIndex: It took 39 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,025 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,322 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,328 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.184.7:44285 (size: 39.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,332 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,657 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,660 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,664 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,718 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,732 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,733 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,733 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,734 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,740 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,788 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,791 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,792 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.184.7:44285 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,793 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,812 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,813 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:22,854 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4636 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:23,077 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:42163 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:23,911 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:42163 (size: 39.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,251 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1408 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,253 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,260 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.498 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,263 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,263 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,265 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.547049 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,431 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.184.7:44285 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:24,437 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:42163 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,672 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,674 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,677 INFO datasources.FileSourceStrategy: Output Data Schema: struct<age: string, gender: string, height_ft: string, weight_lbs: string, systolic_bp: string ... 22 more fields>\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,864 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,881 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,882 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.184.7:44285 (size: 39.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,884 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,901 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,948 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,950 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,950 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,950 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,953 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:26,961 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,019 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,022 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,022 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.184.7:44285 (size: 8.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,023 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,024 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,024 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,029 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,082 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:42163 (size: 8.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:27,896 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:42163 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,126 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:42163 (size: 3.2 MiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,249 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2223 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,249 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,250 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 2.287 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,250 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,251 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,251 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 2.302507 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:29,531 INFO codegen.CodeGenerator: Code generated in 210.366342 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,018 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,168 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,171 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,172 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,172 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,174 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,176 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,202 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 116.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,204 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,205 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.184.7:44285 (size: 35.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,211 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,213 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,213 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,223 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:30,244 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:42163 (size: 35.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,245 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2025 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,246 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,247 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 2.067 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,248 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,248 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,248 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,249 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,333 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,335 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,335 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,335 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,336 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,336 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,352 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 169.3 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,354 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 46.7 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,355 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.184.7:44285 (size: 46.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,356 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,357 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,357 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,360 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,383 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:42163 (size: 46.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,438 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,990 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 631 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,992 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.648 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,994 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,995 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,995 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:32,998 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.663477 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,048 INFO codegen.CodeGenerator: Code generated in 39.341447 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,334 INFO codegen.CodeGenerator: Code generated in 33.466277 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,401 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,402 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,402 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,403 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,404 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,405 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,438 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 40.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,441 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,442 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.184.7:44285 (size: 17.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,442 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,443 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,443 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,446 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:33,474 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:42163 (size: 17.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,341 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 1896 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,343 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,344 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 1.938 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,344 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,345 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,345 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 1.944204 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,478 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.184.7:44285 in memory (size: 35.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,482 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:42163 in memory (size: 35.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,510 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:42163 in memory (size: 17.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,512 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.184.7:44285 in memory (size: 17.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,572 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.184.7:44285 in memory (size: 46.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,573 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:42163 in memory (size: 46.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,613 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.184.7:44285 in memory (size: 8.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,615 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:42163 in memory (size: 8.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,991 INFO codegen.CodeGenerator: Code generated in 104.969196 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:35,999 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,000 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,000 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,000 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,000 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,001 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,006 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 77.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,008 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,009 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.184.7:44285 (size: 25.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,009 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,010 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,010 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,011 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,025 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:42163 (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,212 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 201 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,212 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,213 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.211 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,214 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,214 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,214 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,214 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,374 INFO codegen.CodeGenerator: Code generated in 84.655111 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,385 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,386 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,387 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,387 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,387 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,388 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,391 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 67.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,392 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,393 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.184.7:44285 (size: 19.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,393 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,394 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,394 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,395 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,411 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:42163 (size: 19.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,420 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,559 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 164 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,560 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.171 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,561 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,561 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,562 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,562 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.177499 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,672 INFO codegen.CodeGenerator: Code generated in 84.19733 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,820 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,825 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,825 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,826 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,826 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,826 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,830 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,840 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 32.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,857 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,858 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.184.7:44285 (size: 14.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,859 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,859 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,859 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,861 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:36,877 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:42163 (size: 14.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,348 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1487 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,349 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,349 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.518 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,350 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,350 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,350 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,350 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,350 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,352 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,353 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,354 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.184.7:44285 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,354 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,355 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,355 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,357 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,367 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:42163 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,372 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,421 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 65 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,421 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,422 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.071 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,422 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,422 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,422 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.602616 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,605 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,605 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,605 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,605 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,606 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,607 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,611 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 85.6 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,612 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,613 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.184.7:44285 (size: 28.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,613 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,614 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,614 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,615 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:38,627 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:42163 (size: 28.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,151 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 536 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,151 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,152 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.544 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,152 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,152 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,152 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,152 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,193 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,195 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,195 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,195 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,195 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,197 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,202 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 170.4 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,204 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,205 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.184.7:44285 (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,205 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,206 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,206 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,207 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,218 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:42163 (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,227 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,297 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,297 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,298 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.100 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,298 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,298 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,299 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.104891 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,446 INFO codegen.CodeGenerator: Code generated in 12.437518 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,473 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,475 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,475 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,475 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,476 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,477 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,485 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,487 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,488 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.184.7:44285 (size: 16.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,489 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,490 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,490 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,493 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:39,510 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:42163 (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,973 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 1480 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,973 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,974 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 1.496 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,975 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,975 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:40,976 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 1.501810 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,201 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:42163 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,209 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.184.7:44285 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,234 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.184.7:44285 in memory (size: 28.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,243 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:42163 in memory (size: 28.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,252 INFO codegen.CodeGenerator: Code generated in 98.688774 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,262 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.184.7:44285 in memory (size: 14.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,263 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:42163 in memory (size: 14.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,271 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,271 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,271 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,271 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,272 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,272 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,282 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 78.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,284 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,284 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.184.7:44285 (size: 25.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,285 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,285 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,285 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,287 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,300 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:42163 (size: 25.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,307 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.184.7:44285 in memory (size: 25.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,314 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:42163 in memory (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,345 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.184.7:44285 in memory (size: 16.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,351 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:42163 in memory (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,369 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.184.7:44285 in memory (size: 19.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,375 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:42163 in memory (size: 19.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,408 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:42163 in memory (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,412 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.184.7:44285 in memory (size: 47.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,504 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 217 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,504 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,505 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.232 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,506 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,506 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,506 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,506 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,718 INFO codegen.CodeGenerator: Code generated in 97.359539 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,736 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,740 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,740 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,740 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,740 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,740 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,742 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 67.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,744 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,745 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.184.7:44285 (size: 19.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,745 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,745 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,746 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,747 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,757 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:42163 (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,761 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,819 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 72 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,820 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,821 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.080 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,821 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,821 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,821 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.083006 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,915 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,918 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,919 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,919 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,919 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,919 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,922 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,928 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,930 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,930 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.184.7:44285 (size: 14.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,931 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,931 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,931 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,933 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:41,947 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:42163 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,071 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 138 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,072 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,072 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.149 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,072 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,072 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,073 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,073 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,073 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,075 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,076 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,076 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.184.7:44285 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,077 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,077 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,077 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,078 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,087 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:42163 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,089 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,102 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,102 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,103 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,104 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,104 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,104 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.188103 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,239 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,239 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,239 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,239 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,239 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,240 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,243 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 85.6 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,245 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,245 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.184.7:44285 (size: 28.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,245 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,246 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,246 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,247 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,257 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:42163 (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,630 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 384 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,630 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,631 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.390 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,631 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,632 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,632 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,632 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,676 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,677 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,677 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,677 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,678 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,678 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,684 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 170.5 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,686 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,687 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.184.7:44285 (size: 46.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,687 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,688 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,688 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,689 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,701 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:42163 (size: 46.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,711 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,817 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,817 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,818 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.139 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,818 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,819 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,819 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.143057 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,900 INFO codegen.CodeGenerator: Code generated in 15.589119 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,934 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,936 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,936 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,936 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,936 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,937 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,944 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.5 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,946 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,946 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.184.7:44285 (size: 17.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,947 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,947 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,947 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,948 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:42,962 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:42163 (size: 17.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,895 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 947 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,896 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.958 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,897 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,897 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,897 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:43,897 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.962680 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,059 INFO codegen.CodeGenerator: Code generated in 60.984773 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,067 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,068 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,068 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,068 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,069 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,069 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,074 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 56.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,075 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,076 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.184.7:44285 (size: 19.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,076 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,079 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,079 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,080 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,091 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:42163 (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,285 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 205 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,285 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,286 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.216 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,286 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,287 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,287 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,287 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,433 INFO codegen.CodeGenerator: Code generated in 81.85725 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,449 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,450 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,450 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,450 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,450 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,451 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,453 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 44.4 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,455 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,456 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.184.7:44285 (size: 14.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,456 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,456 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,456 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,458 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,468 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:42163 (size: 14.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,472 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,523 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 66 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,523 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,524 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.072 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,525 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,525 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,525 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.076065 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,578 INFO codegen.CodeGenerator: Code generated in 41.733167 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,642 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,643 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,643 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,643 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,644 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,644 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,645 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,651 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 32.8 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,653 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,654 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.184.7:44285 (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,654 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,655 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,655 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,656 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,666 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:42163 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,777 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 121 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,779 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.131 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,780 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,780 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,780 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,780 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,780 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,781 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,782 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,784 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,784 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.184.7:44285 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,785 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,785 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,785 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,786 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,800 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:42163 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,804 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,813 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,814 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,814 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,814 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,814 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,815 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.172890 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,904 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,904 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,904 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,905 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,905 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,905 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,910 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 85.6 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,912 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,912 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.184.7:44285 (size: 28.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,913 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,913 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,913 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,914 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:44,923 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:42163 (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,248 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 334 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,248 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,253 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.346 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,255 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,256 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,256 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,256 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,269 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:42163 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,276 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.184.7:44285 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,320 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.184.7:44285 in memory (size: 25.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,328 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,329 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,330 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,330 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,330 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,331 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,348 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 170.6 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,350 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,352 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.184.7:44285 (size: 47.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,353 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:42163 in memory (size: 25.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,356 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,356 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,356 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,358 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,377 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:42163 in memory (size: 14.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,378 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:42163 (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,387 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.184.7:44285 in memory (size: 14.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,400 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,428 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:42163 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,440 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.184.7:44285 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,474 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.184.7:44285 in memory (size: 17.5 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,482 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:42163 in memory (size: 17.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,485 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 127 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,485 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,486 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.155 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,486 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,486 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,487 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.158347 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,573 INFO codegen.CodeGenerator: Code generated in 14.022694 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,602 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.184.7:44285 in memory (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,609 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,610 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,610 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,610 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,614 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,615 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,616 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:42163 in memory (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,638 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:42163 in memory (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,640 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 40.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,644 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,645 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.184.7:44285 (size: 17.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,645 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,646 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,646 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,647 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,670 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.184.7:44285 in memory (size: 19.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,677 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:42163 (size: 17.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,694 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.184.7:44285 in memory (size: 19.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,716 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:42163 in memory (size: 19.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,731 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:42163 in memory (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,741 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.184.7:44285 in memory (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,755 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:42163 in memory (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,759 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.184.7:44285 in memory (size: 28.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,770 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.184.7:44285 in memory (size: 46.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:45,780 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:42163 in memory (size: 46.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,143 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 1496 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,143 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,144 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 1.528 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,144 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,145 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,145 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 1.536246 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,323 INFO codegen.CodeGenerator: Code generated in 41.898882 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,329 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,330 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,330 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,330 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,331 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,331 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,336 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 77.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,338 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,338 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.184.7:44285 (size: 25.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,338 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,339 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,339 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,340 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,353 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:42163 (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,648 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 308 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,649 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,650 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.317 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,650 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,650 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,650 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,650 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,830 INFO codegen.CodeGenerator: Code generated in 94.695689 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,865 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,866 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,866 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,867 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,867 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,867 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,869 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 67.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,871 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,872 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.184.7:44285 (size: 19.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,872 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,873 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,874 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,876 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,888 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:42163 (size: 19.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,895 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,957 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 81 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,957 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,959 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.090 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,959 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,959 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:47,959 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.093914 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,022 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,023 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,024 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,024 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,024 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,024 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,026 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,031 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 32.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,033 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,034 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.184.7:44285 (size: 14.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,034 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,034 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,034 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,036 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,049 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:42163 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,229 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 194 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,229 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.203 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,230 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,231 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,233 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,233 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.184.7:44285 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,235 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,236 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,236 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,240 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,256 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:42163 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,259 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,279 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 39 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,279 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,280 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.049 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,281 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,284 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,285 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.262169 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,461 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,461 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,461 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,462 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,462 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,462 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,470 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 75.4 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,472 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,473 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.184.7:44285 (size: 25.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,474 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,474 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,474 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,476 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:48,487 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:42163 (size: 25.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,022 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 546 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.560 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,023 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,054 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,055 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,055 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,056 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,056 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,056 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,064 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 144.2 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,065 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 41.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,066 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.184.7:44285 (size: 41.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,067 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,072 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,072 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,073 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,081 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:42163 (size: 41.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,088 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,156 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,156 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,157 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.099 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,157 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,157 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,157 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.102699 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,170 INFO codegen.CodeGenerator: Code generated in 10.679974 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,238 INFO codegen.CodeGenerator: Code generated in 13.475148 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,276 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,277 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,277 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,277 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,278 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,278 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,288 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 38.3 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,290 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,291 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.184.7:44285 (size: 16.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,296 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,297 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,297 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,298 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4964 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,310 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:42163 (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,848 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 550 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,849 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,849 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.570 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,850 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,850 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,850 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.573862 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,955 INFO codegen.CodeGenerator: Code generated in 33.216605 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,974 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,974 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,974 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,974 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,975 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,975 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,979 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 45.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,980 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,984 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.184.7:44285 (size: 17.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,984 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,984 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,984 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,986 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:49,997 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:42163 (size: 17.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,098 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 112 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,098 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,099 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.123 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,100 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,101 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,101 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,101 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,155 INFO codegen.CodeGenerator: Code generated in 22.239231 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,191 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,192 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,194 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,194 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,195 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,196 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,198 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 33.2 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,203 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,204 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.184.7:44285 (size: 11.5 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,208 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,208 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,208 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,210 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,221 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:42163 (size: 11.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,225 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,251 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,251 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,253 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,253 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,253 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,254 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.062392 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,309 INFO codegen.CodeGenerator: Code generated in 49.503689 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,404 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,405 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,405 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,405 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,405 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,405 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,407 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,412 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 32.8 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,417 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,417 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.184.7:44285 (size: 14.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,417 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,418 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,418 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,419 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,430 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:42163 (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,634 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 215 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,634 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.228 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,635 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,637 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,665 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,666 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.184.7:44285 (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,671 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:42163 in memory (size: 41.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,671 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,671 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,672 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,673 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,674 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.184.7:44285 in memory (size: 41.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,697 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.184.7:44285 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,702 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:42163 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,705 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:42163 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,705 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.184.7:44285 in memory (size: 17.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,707 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:42163 in memory (size: 17.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,709 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.184.7:44285 in memory (size: 14.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,709 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,710 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:42163 in memory (size: 14.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,713 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.184.7:44285 in memory (size: 19.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,714 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:42163 in memory (size: 19.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,717 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.184.7:44285 in memory (size: 28.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,718 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:42163 in memory (size: 28.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,729 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.184.7:44285 in memory (size: 11.5 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,730 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:42163 in memory (size: 11.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,733 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.184.7:44285 in memory (size: 17.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,741 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:42163 in memory (size: 17.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,742 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 69 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,742 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,743 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.107 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,744 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,744 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,744 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.339995 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,745 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.184.7:44285 in memory (size: 47.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,746 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:42163 in memory (size: 47.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,751 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.184.7:44285 in memory (size: 25.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,757 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:42163 in memory (size: 25.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,760 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.184.7:44285 in memory (size: 16.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,766 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:42163 in memory (size: 16.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,771 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.184.7:44285 in memory (size: 25.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,772 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:42163 in memory (size: 25.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,957 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,982 INFO codegen.CodeGenerator: Code generated in 7.38194 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,988 INFO scheduler.DAGScheduler: Registering RDD 191 (count at StatsGenerator.scala:66) as input to shuffle 15\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,988 INFO scheduler.DAGScheduler: Got map stage job 32 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,989 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,989 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,989 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,990 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,993 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 24.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,994 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,995 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.184.7:44285 (size: 11.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,995 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,996 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,996 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:50,997 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,014 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:42163 (size: 11.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,059 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 62 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,059 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,060 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (count at StatsGenerator.scala:66) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,060 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,060 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,060 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,060 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,075 INFO codegen.CodeGenerator: Code generated in 7.898856 ms\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,085 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,086 INFO scheduler.DAGScheduler: Got job 33 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,086 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,087 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,087 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,087 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,089 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,091 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,091 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.184.7:44285 (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,091 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,092 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,092 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,093 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,104 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:42163 (size: 5.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,108 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.0.184.7:55354\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,126 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,126 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,127 INFO scheduler.DAGScheduler: ResultStage 49 (count at StatsGenerator.scala:66) finished in 0.039 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,127 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,127 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,128 INFO scheduler.DAGScheduler: Job 33 finished: count at StatsGenerator.scala:66, took 0.042009 s\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,808 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,823 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,891 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,891 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,897 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,914 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,971 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,971 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,977 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:51,986 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,079 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,079 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,079 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,108 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,108 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-94ffe8ea-fa6e-4dcf-8bd5-7f42cb23f7ef\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,115 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-e01fce4f-3e59-465c-a337-e148fff77abe\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,175 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2025-06-11 03:27:52,176 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n",
      "Baseline generation complete\n"
     ]
    }
   ],
   "source": [
    "# Create model monitor object\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Define baseline input/output locations\n",
    "baseline_data_uri = f's3://{bucket}/{prefix}/cardio_engineered_clean.csv'\n",
    "baseline_results_uri = f's3://{bucket}/{prefix}/baseline-results'\n",
    "\n",
    "# Suggest baseline job\n",
    "baseline_job = monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format={'csv': {'header': True}},\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"Baseline generation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3fc0e-fd1f-4e0e-923a-4e325d564425",
   "metadata": {},
   "source": [
    "Full model monitoring pipeline has been prepared by first creating the SKLearn model object, which wraps the trained logistic regression model and inference script so SageMaker can use it. Then I enable data capture, which collects real-time input data and predictions as the model serves traffic, creating a record of live inference data. After that, I deploy the model as an endpoint to make it accessible for inference while capturing data. Once deployed, I generate a baseline using the fully cleaned and preprocessed training dataset; this allows SageMaker to compute statistics and constraints that define the models expected data distributions. These baseline statistics become the reference point that future data will be compared against to detect drift or anomalies. This full setup ensures that once monitoring jobs are configured, SageMaker can automatically evaluate incoming data for shifts that may impact model accuracy or stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636aeb4-cfe1-4999-96b1-97a027ad988e",
   "metadata": {},
   "source": [
    "* Calculates <b>statistics</b> (distribution, min, max, mean, std, percentiles, etc.)\n",
    "* Generates <b>constraints</b> (rules/thresholds learned from your dataset, e.g., feature X must be within certain boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285f5f8-e12c-40cd-b2c8-55a9876ee418",
   "metadata": {},
   "source": [
    "### Check Constraint Files Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f73e78-2dc6-465c-92d4-7f2a261f186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline statistics and constraints found:\n",
      "cardio_data/baseline-results/constraints.json\n",
      "cardio_data/baseline-results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Your bucket and baseline folder\n",
    "bucket = 'sagemaker-us-east-1-531690656306'\n",
    "baseline_prefix = 'cardio_data/baseline-results/'\n",
    "\n",
    "# List objects in the baseline folder\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=baseline_prefix)\n",
    "\n",
    "# Check and print files\n",
    "if 'Contents' in response:\n",
    "    print(\"Baseline statistics and constraints found:\")\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No baseline files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2c31ccd-181c-46a2-9d5f-98bb4c73d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files containing 'baseline':\n",
      "\n",
      "cardio_data/baseline-results/constraints.json\n",
      "cardio_data/baseline-results/statistics.json\n",
      "cardio_project/cardio_logistic_baseline.ipynb\n",
      "cardio_project/cardio_logistic_baseline_complete.ipynb\n",
      "cardio_project/cardio_logistic_baseline_v2.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Search for all saved baseline results\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'sagemaker-us-east-1-531690656306'\n",
    "\n",
    "# List all files with 'baseline' in the key\n",
    "response = s3.list_objects_v2(Bucket=bucket)\n",
    "\n",
    "print(\"Files containing 'baseline':\\n\")\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        if 'baseline' in key.lower():\n",
    "            print(f\"{key}\")\n",
    "else:\n",
    "    print(\"No objects found in the bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0392fe0e-bfe3-4536-8202-1627f6b1f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./cardio_model_monitoring.ipynb to s3://sagemaker-us-east-1-531690656306/cardio_project/cardio_model_monitoring.ipynb\n",
      "upload: ./cardio_engineered_clean.csv to s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Notebook to S3\n",
    "!aws s3 cp cardio_model_monitoring.ipynb s3://sagemaker-us-east-1-531690656306/cardio_project/cardio_model_monitoring.ipynb\n",
    "!aws s3 cp cardio_engineered_clean.csv s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered_clean.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643765fb-250d-4260-9c23-7499010bef28",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## For Reference Only\n",
    "### <u>File Locations Summary for Model Monitoring Setup</u>\n",
    "\n",
    "#### Trained Model Artifact (used for deployment & endpoint)\n",
    "`s3://sagemaker-us-east-1-531690656306/model/logistic_model.tar.gz`\n",
    "\n",
    "#### Training Dataset (used for baseline generation)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_train.csv`\n",
    "\n",
    "#### Engineered Dataset (cleaned and engineered)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/cardio_engineered_clean.csv`\n",
    "\n",
    "#### Baseline Results Output Folder (generated by model monitor baseline job)\n",
    "`s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/`\n",
    "\n",
    "#### Inside baseline-results:\n",
    "- `statistics.json`  \n",
    "  `s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/statistics.json`\n",
    "\n",
    "- `constraints.json`  \n",
    "  `s3://sagemaker-us-east-1-531690656306/cardio_data/baseline-results/constraints.json`\n",
    "\n",
    "#### Data Capture Location (request/response payloads captured from endpoint)\n",
    "`s3://sagemaker-us-east-1-531690656306/data-capture/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sagemaker-env)",
   "language": "python",
   "name": "sagemaker-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
